---
title: "Selected Exercises from Chapter 2"
output: github_document
---

```{r, echo = FALSE}
library(Cairo)
knitr::opts_chunk$set(
  fig.path = "figs/ch02ex_figs/ch02ex-"
)
```

It turned out to be more straightforward to use **rethinking** instead of **brms** for exercises 1 and 11. Exercises 13 and 21 are done using **brms**.

```{r warning=FALSE, message=FALSE}
library(rethinking)
library(foreign)
library(tools)
```

## 2.1

We'll fit a model where the binomial parameter for each of the options (0 heads, 1 head, 2 heads) is estimated separately.

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e1 <- map2stan(
    alist(
        k ~ dbinom(n, p),
        p <- theta[alt],
        theta[alt] ~ dbeta(4, 4)
    ),
    data = list(
        n = as.integer(c(10, 10, 10)),
        k = as.integer(c(0, 1, 2)),
        alt = as.factor(c("a", "b", "c"))
    ),
    start = list(theta = c(0.5, 0.5, 0.5)),
    control = list(adapt_delta = 0.99999),  # somehow necessary
    iter = 1e4,
    warmup = 1e3
)
```

```{r}
precis(m2e1, depth = 2)
```

Now we combine the samples from all three alternatives gives the desired result.

```{r dev="CairoPNG"}
theta <- extract.samples(m2e1)$theta
dim(theta) <- nrow(theta)*ncol(theta)
dens(theta, adj = 1, xlim = c(0, 1))
```


## 2.2

```{r}
# (coin 1, coin 2)
prior <- c(1, 1)
likelihood <- c(0.4^2, 0.6^2)  # two tails were spun
posterior <- prior*likelihood
( posterior <- posterior/sum(posterior) )
```

```{r}
probs <- c(0.6, 0.4)
# E[E[additional spins needed | TT, coin] | TT]
sum(posterior/probs)  # note E[additional spins needed | TT, coin] = 1/probs
```


## 2.3

### (a)

Instead of using a normal approximation we'll simulate 100,000 samples from the predictive distribution and plot the resulting density.

```{r dev="CairoPNG"}
probs <- c(1/12, 1/6, 1/4)
prior <- c(0.25, 0.5, 0.25)
prob_samples <- sample(probs, 1e5, replace = TRUE, prob = prior)
predictive <- rbinom(1e5, 1000, prob_samples)
# rethinking::dens()
dens(
    predictive,
    xlab = "Number of sixes rolled out of 1000",
    main = "Predictive distribution"
)
```

```{r}
quantile(predictive, probs = c(0.05, 0.25, 0.5, 0.75, 0.95))
```


## 2.9

### (a)

```{r dev="CairoPNG"}
dbeta2 <- function(x, mean, sd, log = FALSE)
    dbeta(
        x,
        shape1 = mean*(mean - mean^2 - sd^2)/sd^2,
        shape2 = (1 - mean)*(mean - mean^2 - sd^2)/sd^2,
        log = log
    )
curve(dbeta2(x, mean = 0.6, sd = 0.3), from = 0, to = 1)
```

```{r dev="CairoPNG"}
curve(
    dbinom(650, 1000, x)*dbeta2(x, 0.6, 0.3),
    from = 0.55, to = 0.75,
    xlab = "theta", ylab = "posterior density",
    yaxt = "n"
)
```


## 2.10

### (a)

It's equally likely that we'll see any of the cars numbered 1 to N, so our likelihood is uniform on (1, 2, ..., N). That is, p(203|N) = 1/N. Our posterior for N|203 is then proportional to **(99/100)^(N-1) / N** for N >= 203.

### (b)

```{r dev="CairoPNG"}
posterior <- function(n) exp(-log(100) + (n-1)*log(99/100) - log(n))
n.seq <- 203:1e5
coef <- 1/sum(posterior(n.seq))
plot(203:1e3, coef*posterior(203:1e3), type = "l", xlab = "N", ylab = "posterior")
# posterior mean
( mean <- sum(coef*(n.seq)*posterior(n.seq)) )
# posterior standard deviation
sqrt(sum(coef*(n.seq)^2*posterior(n.seq)) - mean^2)
```

### (c)

The Fisher information for N is **E[(d(-log N)/dN)^2 | N] = 1/N^2**, so Jeffrey's principle leads to the noninformative prior **p(N) = 1/N**. Thus our posterior is proportional to 1/N^2 for N >= 203.

```{r dev="CairoPNG"}
posterior <- function(n) 1/n^2
coef <- 1/(pi^2/6 - sum(posterior(1:202)))
plot(203:1e3, coef*posterior(203:1e3), type = "l", xlab = "N", ylab = "posterior")
```

The mean and standard deviation of this distribution are infinite.


## 2.11

### (a, b)

Instead of using a grid model, we'll use **rethinking** to obtain the posterior samples.

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e11 <- map2stan(
    alist(
        y ~ dcauchy(theta, 1),
        theta ~ dunif(0, 100)
    ),
    data = list(y = c(43, 44, 45, 46.5, 47.5)),
    iter = 6e3,
    warmup = 1e3,
    chains = 4,
    cores = 4
)
```

```{r}
precis(m2e11)
```

```{r dev="CairoPNG"}
theta <- extract.samples(m2e11)$theta
dens(theta, xlab = "theta", main = "Posterior for theta")
```

### (c)

```{r dev="CairoPNG"}
predictive <- rcauchy(1e3, theta)
hist(predictive, breaks = 500, xlim = c(0, 100), xlab = "y", main = "Predictive distribution")
```


## 2.13

```{r}
airlines <- data.frame(
    year = as.integer(c(1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985)),
    fatal_accidents = c(24, 25, 31, 31, 22, 21, 26, 20, 16, 22),
    passenger_deaths = c(734, 516, 754, 877, 814, 362, 764, 809, 223, 1066),
    death_rate = c(0.19, 0.12, 0.15, 0.16, 0.14, 0.06, 0.13, 0.13, 0.03, 0.15)
)
```

This is the first problem where I can use **brms** easily.

```{r warning=FALSE, message=FALSE}
library(brms)
library(coda)

# The following helper functions are from the 'rethinking' package.

col.alpha <- function( acol , alpha=0.2 ) {
    acol <- col2rgb(acol)
    acol <- rgb(acol[1]/255,acol[2]/255,acol[3]/255,alpha)
    acol
}

col.desat <- function( acol , amt=0.5 ) {
    acol <- col2rgb(acol)
    ahsv <- rgb2hsv(acol)
    ahsv[2] <- ahsv[2] * amt
    hsv( ahsv[1] , ahsv[2] , ahsv[3] )
}

rangi2 <- col.desat("blue", 0.5)
```

### (a)

Just using an improper (flat) prior here.

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e_13_1 <- brm(
    fatal_accidents ~ 1,
    family = poisson(),
    data = airlines
)
```

```{r}
summary(m2e_13_1)
```

```{r dev="CairoPNG"}
theta <- exp(as.data.frame(m2e_13_1)$b_Intercept)
plot(density(theta), xlab = "theta", ylab = "density", main = "Posterior for theta")
```

#### Predicting the number of accidents in 1986

```{r}
predictive <- rpois(1e5, theta)
HPDinterval(as.mcmc(predictive))[1,]
```

### (b)

```{r}
# add a column containing how many hundred billion passenger miles were flown
airlines$miles <- airlines$passenger_deaths/airlines$death_rate * 1e-3
airlines
```

We'll fit the model on the log scale using an adaptive normal prior on the distribution of rates.

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e_13_2 <- brm(
    fatal_accidents ~ (1 | year) + offset(log(miles)),
    family = poisson(),
    data = airlines,
    iter = 9e3,
    warmup = 1e3,
    chains = 4,
    cores = 4,
    control = list(adapt_delta = 0.99)
)
```

```{r}
summary(m2e_13_2)
```

```{r}
samples <- as.mcmc(m2e_13_2, combine_chains = TRUE)
year_posts <- sapply(3:12, function(i) exp(samples[,1] + samples[,i]))
HPDIs <- apply(year_posts, 2, function(x) HPDinterval(as.mcmc(x)))
data.frame(
    year = airlines$year,
    estimate = round(apply(year_posts, 2, mean), 2),
    sd = round(apply(year_posts, 2, sd), 2),
    HPDI_95 = apply(HPDIs, 2, function(x) paste(round(x[1], 2), "to", round(x[2], 2)))
)
```

These are the Bayes-adjusted fatal accident rates (fatal accidents per hundred billion passenger miles) for each year.

#### Predicting the number of accidents in 1986

There a few ways we could estimate the number of fatal accidents for 1986.

The best place to start would be to compare the two models we've fit. We'll estimate their predictive power using [leave-one-out cross validation](https://link.springer.com/article/10.1007/s11222-016-9696-4).

```{r message=FALSE}
loo(m2e_13_1, m2e_13_2, reloo = TRUE)
```

The LOOIC estimates that the first model, which didn't model the different years separately, certainly has more predictive power than the second model. We can be confident in our earlier estimate of a 95% prediction interval of 14 to 33 accidents.

One benefit of the second model is that it explicitly models variation of the fatal accident rates between years. It estimated the distribution of log accident rates to have a mean of 1.42 and a standard deviation of 0.34. We can use this uncertainty to construct a posterior for the accident rate of a new year.

```{r dev="CairoPNG"}
# Here, samples[,1] contains the samples for the mean, and
# samples[,2] contains the samples for the standard deviation.
log_accident_rate <- rnorm(nrow(samples), mean = samples[,1], sd = samples[,2])
accident_rate <- exp(log_accident_rate)
plot(
    density(accident_rate),
    xlim = c(0, 20),
    xlab = "fatal accident rate", ylab = "density",
    main = "Posterior for fatal accident rate"
)
```

We can then use this posterior to create a predictive distribution.

```{r dev="CairoPNG"}
predictive <- rpois(length(accident_rate), 8*accident_rate)
plot(
    table(predictive)/length(predictive),
    xlim = c(0, 100),
    xlab = "number of fatal accidents",
    ylab = "probability"
)
```

And here's the 95% predictive interval this gives us:

```{r}
HPDinterval(as.mcmc(predictive))[1,]
```

Clearly this is much more conservative than the last estimate. This is a good thing!

Now, we have ignored the fact that our model treats the data from each year as exchangeable. We might suspect, or the keen eye might have noticed, that the fatal accident rates seem to have decreased over time.

```{r dev="CairoPNG"}
plot(1976:1985, apply(year_posts, 2, mean), xlab = "year", ylab = "fatal accident rate", ylim = c(1.5, 8))
for(year in 1976:1985)
    lines(x = c(year, year), y = HPDIs[,year - 1975])
```

Neither of the previous models have taken this into account. The simplest way we could do so is to assume that the accident rate will be about the same as it was the last year, in 1985, obtaining the following estimate.

```{r}
predict(m2e_13_2, newdata = list(year = 1985, miles = 8))
```

To squeeze a little more blood from this rock, we could even fit a regression line over these rates, taking into account the errors in their estimates. We'll fit it on the log scale to take into account that the rates should be positive.

```{r}
log_year_posts <- sapply(3:12, function(i) samples[,1] + samples[,i])
log_HPDIs <- apply(log_year_posts, 2, function(x) HPDinterval(as.mcmc(x)))
log_estimates <- data.frame(
    year = airlines$year,
    log_estimate = round(apply(log_year_posts, 2, mean), 3),
    sd = round(apply(log_year_posts, 2, sd), 3),
    HPDI_95 = apply(HPDIs, 2, function(x) paste(round(x[1], 2), "to", round(x[2], 2)))
)
log_estimates$year_s <- (log_estimates$year - mean(log_estimates$year))/sd(log_estimates$year)
log_estimates
```

```{r dev="CairoPNG"}
plot(1976:1985, apply(log_year_posts, 2, mean), xlab = "year", ylab = "log fatal accident rate", ylim = c(0.5, 2.25))
for(year in 1976:1985)
    lines(x = c(year, year), y = log_HPDIs[,year - 1975])
```

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e_13_3 <- brm(
    log_estimate | se(sd, sigma = TRUE) ~ year_s,
    data = log_estimates,
    iter = 9e3,
    warmup = 1e3,
    chains = 4,
    cores = 4
)
```

```{r}
summary(m2e_13_3)
```

Here's what the regression line and its 89% prediction interval look like against the estimated fatal accident rates.

```{r dev="CairoPNG"}
post <- as.data.frame(m2e_13_3)
year.seq <- seq(from = 1.1*min(log_estimates$year_s), to = 1.1*max(log_estimates$year_s), length.out = 30)
link <- sapply(year.seq, function(y) exp(post$b_Intercept + y*post$b_year_s))
link.mu <- apply(link, 2, mean)
link.PI <- apply(link, 2, function(x) HPDinterval(as.mcmc(x), prob = 0.89))

plot(
    log_estimates$year_s, apply(year_posts, 2, mean),
    xlab = "year", ylab = "fatal accident rate",
    ylim = c(1.5, 8),
    xaxt = "n"
)

for(i in 1:10)
    lines(x = c(log_estimates$year_s[i], log_estimates$year_s[i]), y = HPDIs[,i])

lines(year.seq, link.mu)

polygon(
    c(year.seq, rev(year.seq)), c(link.PI[1,], rev(link.PI[2,])),
    col = col.alpha("black", 0.15), border = NA
)

at <- log_estimates$year_s
labels <- log_estimates$year
axis( side=1 , at=at , labels=labels )
```

Using the prediction from this regression we can compute a posterior for the accident rate in 1986 by simulating a normal distribution with the sampled means and standard deviations.

```{r dev="CairoPNG"}
year <- (1986 - mean(log_estimates$year))/sd(log_estimates$year)
mu <- post$b_Intercept + year*post$b_year_s
log_accident_rate <- rnorm(length(mu), mean = mu, sd = post$sigma)
accident_rate <- exp(log_accident_rate)
plot(
    density(accident_rate),
    xlab = "fatal accident rate", ylab = "density",
    main = "Posterior for 1986 fatal accident rate"
)
```

And we'll compute the corresponding posterior predictive distribution.

```{r dev="CairoPNG"}
predictive <- rpois(length(accident_rate), 8*accident_rate)
plot(
    table(predictive)/length(predictive),
    xlim = c(0, 50),
    xlab = "number of fatal accidents",
    ylab = "probability",
    main = "Posterior predictive distribution for number of fatal accidents in 1986"
)
```

This predictive distribution yields the following estimate and corresponding 95% prediction interval.

```{r}
interval <- HPDinterval(as.mcmc(predictive))[1,]
data.frame(
    year = 1986,
    fatal_accidents = round(mean(predictive)),
    sd = round(sd(predictive), 2),
    HPDI_95 = paste(interval[1], "to", interval[2])
)
```

Compare this with the predictive interval from part (a).

### (c)

Now we model the number of passenger deaths as a Poisson random variable, again using an improper prior.

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e_13_4 <- brm(
    passenger_deaths ~ 1,
    family = poisson(),
    data = airlines
)
```

```{r}
summary(m2e_13_4)
```

```{r dev="CairoPNG"}
theta <- exp(as.data.frame(m2e_13_4)$b_Intercept)
plot(density(theta), xlab = "theta", ylab = "density", main = "Posterior for theta")
```

#### Predicting the number of passenger deaths in 1986

```{r}
predictive <- rpois(1e5, theta)
HPDinterval(as.mcmc(predictive))[1,]
```

### (d)

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e_13_5 <- brm(
    passenger_deaths ~ (1 | year) + offset(log(miles)),
    family = poisson(),
    data = airlines,
    iter = 9e3,
    warmup = 1e3,
    chains = 4,
    cores = 4,
    control = list(adapt_delta = 0.99)
)
```

```{r}
summary(m2e_13_5)
```

```{r}
samples <- as.mcmc(m2e_13_5, combine_chains = TRUE)
year_posts <- sapply(3:12, function(i) exp(samples[,1] + samples[,i]))
HPDIs <- apply(year_posts, 2, function(x) HPDinterval(as.mcmc(x)))
data.frame(
    year = airlines$year,
    estimate = round(apply(year_posts, 2, mean), 2),
    sd = round(apply(year_posts, 2, sd), 2),
    HPDI_95 = apply(HPDIs, 2, function(x) paste(round(x[1], 2), "to", round(x[2], 2)))
)
```

These are the Bayes-adjusted passenger death rates (passenger deaths per hundred billion passenger miles) for each year.

#### Predicting the number of accidents in 1986

We again compare our models using LOO.

```{r message=FALSE}
loo(m2e_13_4, m2e_13_5, reloo = TRUE)
```

In this case the model which estimates separate effects for each year is expected to have FAR more predictive power than the first model. Here is the estimated distribution of passenger death rates:

```{r dev="CairoPNG"}
death_rate <- exp(rnorm(nrow(samples), mean = samples[,1], sd = samples[,2]))
plot(
    density(death_rate[death_rate < 800]),  # remove huge outliers for the plot
    xlim = c(0, 600),
    xlab = "passenger death rate", ylab = "density",
    main = "Posterior for passenger death rate"
)
```

We then use this posterior to create a predictive distribution.

```{r dev="CairoPNG"}
predictive <- rpois(length(death_rate), 8*death_rate)
plot(
    density(predictive[predictive < 5300]),  # remove huge outliers for the plot
    xlim = c(0, 4000),
    xlab = "number of passenger deaths",
    ylab = "density",
    main = "Predictive distribution for passenger deaths in 1986"
)
```

And here's the 95% predictive interval this gives us:

```{r}
HPDinterval(as.mcmc(predictive))[1,]
```

This seems like the best estimate we can get with the data we have. There isn't an obvious trend in the death rates, so we may as well assume that the years are exchangeable.

```{r dev="CairoPNG"}
plot(1976:1985, apply(year_posts, 2, mean), xlab = "year", ylab = "passenger death rate", ylim = c(25, 205))
for(year in 1976:1985)
    lines(x = c(year, year), y = HPDIs[,year - 1975])
```

### (e)

It's arguably less reasonable to model the number of passenger deaths using a Poisson likelihood because they generally require an accident to happen first. Modeling the numbers of deaths and the occurrences of accidents together would be a better approach.


## 2.21

The data for this exercise can be downloaded from [Gelman's website](http://www.stat.columbia.edu/~gelman/book/data/).

The only columns we need from the Pew Research Center data are "ideo" and "state".

```{r}
pew <- read.dta("pew_research_center_june_elect_wknd_data.dta")
pew <- data.frame(ideo = pew$ideo, state = pew$state)
pew <- pew[complete.cases(pew) & pew$state != "hawaii" & pew$state != "alaska",]
pew <- droplevels(pew)
head(pew)
```

We'll tally each respondent identifying as "very liberal" within each state.

```{r}
liberals <- data.frame(
    very_liberal = as.integer(by(pew, pew$state, function(x) sum(grepl("very liberal", x$ideo)))),
    state = levels(pew$state),
    total_surveyed = as.integer(by(pew, pew$state, function(x) nrow(x)))
)
liberals
```

And all we need from the election results data are the state names and Obama's vote shares.

```{r}
election <- read.csv("2008ElectionResult.csv")
election <- election[election$state != "Alaska" & election$state != "Hawaii",]
election$state <- as.character(election$state)
election[election$state == "District of Columbia", 1] <- "washington dc"
election$state <- as.factor(tolower(election$state))
election <- droplevels(election)
election <- data.frame(state = election$state, vote_Obama_pct = election$vote_Obama_pct)
election$stateabbr <- sapply(
    as.character(election$state),
    function(s) ifelse(s == "washington dc", "DC", state.abb[grep(toTitleCase(s), state.name)][1])
)
head(election)
```

### The model

We used a Poisson likelihood in the chapter, but pulling someone out of the population at random and asking them "Do you identify as 'very liberal'?" just feels more like a Bernoulli trial to me. Maybe it's ill-advised, but I'll opt for a binomial likelihood instead. Since the observed proportions of very-liberals in each state are small (<0.1), the corresponding Poisson distributions would approximate our Binomial distributions. So this choice probably won't affect the inferences much anyway.

Similar to what we did in exercise 2.13, we'll fit the model on the *logistic* scale using an adaptive normal prior on the distribution of proportions.

```{r warning=FALSE, message=FALSE, results=FALSE}
m2e_21_1 <- brm(
    very_liberal | trials(total_surveyed) ~ (1 | state),
    family = binomial("logit"),
    data = liberals,
    iter = 9e3,
    warmup = 1e3,
    chains = 4,
    cores = 4
)
```

```{r}
summary(m2e_21_1)
```

```{r}
samples <- as.mcmc(m2e_21_1, combine_chains = TRUE)
state_posts <- sapply(3:51, function(i) inv_logit_scaled(samples[,1] + samples[,i]))
HPDIs <- apply(state_posts, 2, function(x) HPDinterval(as.mcmc(x)))
estimates <- data.frame(
    state = levels(liberals$state),
    proportion = round(apply(state_posts, 2, mean), 4),
    sd = round(apply(state_posts, 2, sd), 4),
    HPDI_95 = apply(HPDIs, 2, function(x) paste(round(x[1], 2), "to", round(x[2], 2)))
)
estimates
```

These are the Bayes-adjusted proportions of very-liberals in each state, along with the standard deviations and 95% density intervals of their posteriors.

```{r}
# lowest estimated proportion of very-liberals
estimates[which.min(estimates$proportion),]
# highest estimated proportion of very-liberals
estimates[which.max(estimates$proportion),]
```

### (a)

```{r dev="CairoPNG"}
d1 <- merge(liberals, election)
plot(
    very_liberal/total_surveyed ~ vote_Obama_pct,
    data = d1,
    xlim = c(30, 93),
    xlab = "Obama's vote share", ylab = "Observed proportion of very-liberals",
    type = "n"
)
text(x = d1$vote_Obama_pct, y = d1$very_liberal/d1$total_surveyed, labels = d1$stateabbr)
```


### (b)

```{r dev="CairoPNG"}
d2 <- merge(estimates, election)
plot(
    proportion ~ vote_Obama_pct,
    data = d2,
    xlim = c(30, 93),
    xlab = "Obama's vote share", ylab = "Bayes-adjusted proportion of very-liberals",
    type = "n"
)
text(x = d2$vote_Obama_pct, y = d2$proportion, labels = d2$stateabbr)
```

### (c)

```{r dev="CairoPNG"}
d3 <- merge(d1, d2)
plot(
    very_liberal/total_surveyed ~ total_surveyed,
    data = d3,
    xlab = "Number of respondents", ylab = "Observed proportion of very-liberals",
    type = "n"
)
text(x = d3$total_surveyed, y = d3$very_liberal/d3$total_surveyed, labels = d3$stateabbr)
```

```{r dev="CairoPNG"}
plot(
    proportion ~ total_surveyed,
    data = d3,
    xlab = "Number of respondents", ylab = "Bayes-adjusted proportion of very-liberals",
    type = "n"
)
text(x = d3$total_surveyed, y = d3$proportion, labels = d3$stateabbr)
```

***

[Antonio R. Vargas](https://github.com/szego)

12 Nov 2018



















































